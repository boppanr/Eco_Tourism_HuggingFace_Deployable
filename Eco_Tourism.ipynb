{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Review Genie - A conversation Chatbot for an Echo Tourism Application\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "CkaZ15bkt6SM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS3n2y8wPw5g"
      },
      "source": [
        "## Basics of RAG\n",
        "\n",
        "Before we start coding, lets go over a few questions and get it clarified.\n",
        "\n",
        "### 1. What is RAG?\n",
        "Imagine you're writing an article about climate change, but instead of relying only on what you remember, you search online for recent studies and data to support your writing. RAG works the same way—it combines a powerful LLMs with a search system that retrieves relevant information from an external knowledge source, like a database or documents. This helps generate more accurate and informative responses.\n",
        "\n",
        "### 2. Why is RAG important?\n",
        "RAG is crucial because LLM models, like ChatGPT, can sometimes \"hallucinate\" or provide outdated or incorrect information. By retrieving facts from trusted sources before generating responses, RAG ensures the answers are more reliable, up-to-date, and contextually relevant.\n",
        "\n",
        "### 3. What’s the difference between RAG and a standard LLM chatbot?\n",
        "A standard chatbot relies only on pre-trained knowledge, which may be limited or outdated. RAG-enhanced chatbots, however, actively retrieve fresh, relevant information from external sources, ensuring better accuracy and up-to-date insights.\n",
        "\n",
        "### 4. What are the key components of RAG?\n",
        "RAG consists of two main parts:\n",
        "\n",
        "- Retriever: Finds the most relevant documents or data from a knowledge base (e.g., a search engine or database).\n",
        "- Generator: Uses the retrieved information to produce a coherent and accurate response.\n",
        "\n",
        "### 5. Usecases in real-life\n",
        "- Customer Support: LLM chatbots retrieve knowledge base articles to provide better responses to customer queries.\n",
        "- Healthcare: Doctors can get AI-assisted summaries of patient records and the latest medical research.\n",
        "- Legal Services: Lawyers can search through legal documents and case studies to build stronger cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TYwjqpUdeS5"
      },
      "source": [
        "\n",
        "\n",
        "Key Objectives - our goals are as follows:\n",
        "\n",
        "- Understanding the overall business problem\n",
        "- Identifying the key milestones that we have to close\n",
        "- Understand the apply the key tools that we need here\n",
        "- Building a simple POC app, that will set the groundwork for the subsequent weeks.\n",
        "\n",
        "\n",
        "\n",
        "**Structure of this Notebook**\n",
        "\n",
        "- Building ReviewGenie POC\n",
        "  - Data Preparation\n",
        "  - Vector Store Setup\n",
        "  - Building the chatbot\n",
        "  - Building a simple Gradio UI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-9ZmExzDRva"
      },
      "source": [
        "### Understanding the Limitation of the LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJLYV5B_YWGD"
      },
      "source": [
        "### Interpretation:\n",
        "Why is the LLM not able to answer the query?\n",
        "\n",
        "\n",
        "\n",
        "#### Do it yourself:\n",
        "Try changing the model to `gpt-4o-mini` and observe how the output changes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXHhy-hcEMyy"
      },
      "source": [
        "### Making the LLM context-aware\n",
        "\n",
        "Next Step: Let's check Uber's [financial report ](https://s23.q4cdn.com/407969754/files/doc_events/2024/May/06/2023-annual-report.pdf)\n",
        "\n",
        "On Page 54, of the above document it states:\n",
        "\n",
        "\"Revenue was 37.3 billion, up 17% year-over-year. Mobility revenue increased 5.8 billion primarily attributable to an increase in\n",
        "Mobility Gross Bookings of......\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKzjA8hmHtaA"
      },
      "source": [
        "### Basic RAG app architecture\n",
        "\n",
        "In the previous example, we manually retrieved the context from the given file which for all purposes is impractical (duh!!)\n",
        "\n",
        "Therefore, we have to devise a strategy that enables us to:\n",
        "\n",
        "- Take the query from the user\n",
        "- Identify the documents from the external source that might be relevant for the query.\n",
        "- Pass those documents' information as context to the LLM\n",
        "- LLM then generates the final response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msqpnuzuJHYY"
      },
      "source": [
        "To do the above, we can follow a simple standard architecture as shown below (Image source - https://huyenchip.com/2024/07/25/genai-platform.html)\n",
        "\n",
        "<center><img src=\"https://huyenchip.com/assets/pics/genai-platform/3-rag.png\" width=500 height=400/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXm08cxzLsia"
      },
      "source": [
        "As you can see in the above image, the retriever would be the key component of this entire architecture.\n",
        "\n",
        "To build the retriever, we have to follow these steps:\n",
        "\n",
        "- Connect to the document source\n",
        "- Break the documents down to manageable chunks. This is due to the fact that taking in the entire document source for building the context will exceed the token limits of the LLM. This process is also called **Chunking**.\n",
        "- Perform a search for the most relevant chunks based on the given query.\n",
        "- Pass those relevant chunks to the LLM.\n",
        "\n",
        "For performing the search or retrieval process, we will be following an **embedding-based approach.**\n",
        "\n",
        "<center><img src=\"https://cdn.prod.website-files.com/640248e1fd70b63c09bd3d09/653fd23f1565c0c1da063efc_Semantic%20Search%20Text%20Embeddings%20(1).png\" width =500/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MPW_40jNLDn"
      },
      "source": [
        "### Understanding Embedding based approach\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "In the embedding based approach:\n",
        "\n",
        "- We convert the document chunks in the database to vector embeddings and store it in a vector store.\n",
        "\n",
        "- Convert the given user query to an embedding.\n",
        "\n",
        "- Find the document chunks whose vector embeddings are closest to the given query embedding using a vector search algorithm like FAISS (Facebook AI Similarity Search)\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*h_btyitJX79d-gFE8RaMQg.png\" width=500/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7aMQOXtON5U"
      },
      "source": [
        "### Tools for building the RAG App\n",
        "\n",
        "Now that we are familiar with the overall architecture, we can now go ahead and structure the tools that we'll use for the upcoming demonstration:\n",
        "\n",
        "- OpenAI LLM (model - GPT 4o-mini): This will be our primary model for generating the responses\n",
        "- LangChain: Langchain is a powerful framework for orchestrating different layers in the RAG app. We shall use this to build the retriever end-to-end and also connect with other tools for tasks such as\n",
        "    - Chunking - RecursiveCharacterTextSplitter\n",
        "    - Embedding Model - OpenAIEmbeddings\n",
        "    - Vector Search Model - FAISS\n",
        "- Gradio: This will help in building a simple UI at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey558a81QcXs"
      },
      "source": [
        "\n",
        "*A basic chatbot that can answer customer queries*\n",
        "\n",
        "\n",
        "\n",
        "<center><img src=\"https://www.pranathiss.com/static/assets/images/ai-powered-chatBot.webp\" width=500/></center>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQfzsw36du3S"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2OGXS6YSl5Y"
      },
      "source": [
        "### Steps:\n",
        "\n",
        "1. **Data Preparation**:\n",
        "   - Load and process the dataset using pandas\n",
        "\n",
        "2. **Vector Store Setup**:\n",
        "   - Convert product descriptions into embeddings.\n",
        "   - Store embeddings in a vector database.\n",
        "\n",
        "3. **Building the Chatbot**:\n",
        "   - Use LangChain to create an LLM pipeline.\n",
        "   - Develop a simple chatbot to answer product-related queries.\n",
        "\n",
        "4. **Creating a UI**:\n",
        "   - Implement a Gradio-based UI for user interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "ekric37zU6aV",
        "outputId": "5f3035cd-3726-4e14-db6e-1330196cb897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.2)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.38)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.11.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.120.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.4)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.120.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.4)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install --upgrade langchain langchain-openai faiss-cpu openai langchain-community\n",
        "\n",
        "!pip install -U langchain-core langchain-text-splitters gradio faiss-cpu tiktoken\n",
        "\n",
        "!pip install --upgrade gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KqC1rIL7IyXt"
      },
      "outputs": [],
      "source": [
        "# Importing the KaggleHub library to interact with datasets and models available on Kaggle.\n",
        "import kagglehub\n",
        "\n",
        "# Importing the CSV module for reading and writing CSV files.\n",
        "import csv\n",
        "\n",
        "# Importing pandas for data manipulation and analysis.\n",
        "import pandas as pd\n",
        "\n",
        "# Importing numpy for numerical operations and handling arrays efficiently.\n",
        "import numpy as np\n",
        "\n",
        "# Importing os to interact with the operating system, such as environment variables and file paths.\n",
        "import os\n",
        "\n",
        "# Importing getpass to securely handle user input (e.g., API keys or passwords).\n",
        "import getpass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9Vphy17StbK"
      },
      "source": [
        "### STEP 1: Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sh9WpGhWRpCU",
        "outputId": "a26d574f-1579-4a19-a68f-fa6a19d7a105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0XiPvpp1FxKb"
      },
      "outputs": [],
      "source": [
        "# Loading the data\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/tourism_resource_dataset.csv\",index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MznuqvAmRx_g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "cb3bc040-db62-41cf-aba0-351dec97ab93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    location_id  visitor_count  resource_usage_rate  \\\n",
              "timestamp                                                             \n",
              "2024-12-01 00:00:00     LOC_003            808             0.907638   \n",
              "2024-12-01 01:00:00     LOC_001            948             0.974266   \n",
              "2024-12-01 02:00:00     LOC_003            292             0.321912   \n",
              "2024-12-01 03:00:00     LOC_003            592             0.811889   \n",
              "2024-12-01 04:00:00     LOC_001             89             0.936667   \n",
              "2024-12-01 05:00:00     LOC_001            278             0.900152   \n",
              "2024-12-01 06:00:00     LOC_003            597             0.975164   \n",
              "2024-12-01 07:00:00     LOC_002            969             0.832066   \n",
              "2024-12-01 08:00:00     LOC_003            272             0.609609   \n",
              "2024-12-01 09:00:00     LOC_003             55             0.518366   \n",
              "\n",
              "                     temperature  air_quality_index  noise_level  season  \\\n",
              "timestamp                                                                  \n",
              "2024-12-01 00:00:00    19.368864                127    51.506727  summer   \n",
              "2024-12-01 01:00:00    17.404945                 37    55.901717  autumn   \n",
              "2024-12-01 02:00:00    16.366819                113    68.533024  winter   \n",
              "2024-12-01 03:00:00    20.266316                 52    85.301039  autumn   \n",
              "2024-12-01 04:00:00    15.922471                145    52.258779  summer   \n",
              "2024-12-01 05:00:00    26.343416                141    70.581182  spring   \n",
              "2024-12-01 06:00:00    20.676569                134    54.193750  summer   \n",
              "2024-12-01 07:00:00    31.490696                 47    87.103858  spring   \n",
              "2024-12-01 08:00:00    16.484817                 30    62.670967  spring   \n",
              "2024-12-01 09:00:00    19.527030                 66    35.370598  autumn   \n",
              "\n",
              "                     peak_hour_flag  visitor_satisfaction  sensor_noise_flag  \\\n",
              "timestamp                                                                      \n",
              "2024-12-01 00:00:00               0              5.502615                  1   \n",
              "2024-12-01 01:00:00               0              4.736401                  0   \n",
              "2024-12-01 02:00:00               1              2.522827                  0   \n",
              "2024-12-01 03:00:00               1              2.687745                  1   \n",
              "2024-12-01 04:00:00               1              1.094965                  1   \n",
              "2024-12-01 05:00:00               1              1.822836                  0   \n",
              "2024-12-01 06:00:00               1              6.011548                  0   \n",
              "2024-12-01 07:00:00               0              9.026858                  0   \n",
              "2024-12-01 08:00:00               0              3.584483                  0   \n",
              "2024-12-01 09:00:00               0              3.949725                  1   \n",
              "\n",
              "                     resource_prediction resource_allocation  t_sne_dim1  \\\n",
              "timestamp                                                                  \n",
              "2024-12-01 00:00:00             0.857819                high   -4.576337   \n",
              "2024-12-01 01:00:00             0.961133                high  -28.314085   \n",
              "2024-12-01 02:00:00             0.306956                 low    1.329948   \n",
              "2024-12-01 03:00:00             0.701945              medium  -11.921675   \n",
              "2024-12-01 04:00:00             0.512834              medium   -6.068825   \n",
              "2024-12-01 05:00:00             0.589076              medium  -30.603321   \n",
              "2024-12-01 06:00:00             0.786082              medium   -1.928188   \n",
              "2024-12-01 07:00:00             0.900533                high  -22.911472   \n",
              "2024-12-01 08:00:00             0.440805                 low   15.556006   \n",
              "2024-12-01 09:00:00             0.286683                 low   -4.017957   \n",
              "\n",
              "                     t_sne_dim2  \n",
              "timestamp                        \n",
              "2024-12-01 00:00:00    0.582736  \n",
              "2024-12-01 01:00:00   20.022820  \n",
              "2024-12-01 02:00:00    5.881103  \n",
              "2024-12-01 03:00:00   20.376535  \n",
              "2024-12-01 04:00:00   -4.793058  \n",
              "2024-12-01 05:00:00    2.003588  \n",
              "2024-12-01 06:00:00  -13.306153  \n",
              "2024-12-01 07:00:00    6.416325  \n",
              "2024-12-01 08:00:00    3.516501  \n",
              "2024-12-01 09:00:00  -26.208872  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23046d6a-d1d5-47dd-a321-08cc72889c4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location_id</th>\n",
              "      <th>visitor_count</th>\n",
              "      <th>resource_usage_rate</th>\n",
              "      <th>temperature</th>\n",
              "      <th>air_quality_index</th>\n",
              "      <th>noise_level</th>\n",
              "      <th>season</th>\n",
              "      <th>peak_hour_flag</th>\n",
              "      <th>visitor_satisfaction</th>\n",
              "      <th>sensor_noise_flag</th>\n",
              "      <th>resource_prediction</th>\n",
              "      <th>resource_allocation</th>\n",
              "      <th>t_sne_dim1</th>\n",
              "      <th>t_sne_dim2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2024-12-01 00:00:00</th>\n",
              "      <td>LOC_003</td>\n",
              "      <td>808</td>\n",
              "      <td>0.907638</td>\n",
              "      <td>19.368864</td>\n",
              "      <td>127</td>\n",
              "      <td>51.506727</td>\n",
              "      <td>summer</td>\n",
              "      <td>0</td>\n",
              "      <td>5.502615</td>\n",
              "      <td>1</td>\n",
              "      <td>0.857819</td>\n",
              "      <td>high</td>\n",
              "      <td>-4.576337</td>\n",
              "      <td>0.582736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-01 01:00:00</th>\n",
              "      <td>LOC_001</td>\n",
              "      <td>948</td>\n",
              "      <td>0.974266</td>\n",
              "      <td>17.404945</td>\n",
              "      <td>37</td>\n",
              "      <td>55.901717</td>\n",
              "      <td>autumn</td>\n",
              "      <td>0</td>\n",
              "      <td>4.736401</td>\n",
              "      <td>0</td>\n",
              "      <td>0.961133</td>\n",
              "      <td>high</td>\n",
              "      <td>-28.314085</td>\n",
              "      <td>20.022820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-01 02:00:00</th>\n",
              "      <td>LOC_003</td>\n",
              "      <td>292</td>\n",
              "      <td>0.321912</td>\n",
              "      <td>16.366819</td>\n",
              "      <td>113</td>\n",
              "      <td>68.533024</td>\n",
              "      <td>winter</td>\n",
              "      <td>1</td>\n",
              "      <td>2.522827</td>\n",
              "      <td>0</td>\n",
              "      <td>0.306956</td>\n",
              "      <td>low</td>\n",
              "      <td>1.329948</td>\n",
              "      <td>5.881103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-01 03:00:00</th>\n",
              "      <td>LOC_003</td>\n",
              "      <td>592</td>\n",
              "      <td>0.811889</td>\n",
              "      <td>20.266316</td>\n",
              "      <td>52</td>\n",
              "      <td>85.301039</td>\n",
              "      <td>autumn</td>\n",
              "      <td>1</td>\n",
              "      <td>2.687745</td>\n",
              "      <td>1</td>\n",
              "      <td>0.701945</td>\n",
              "      <td>medium</td>\n",
              "      <td>-11.921675</td>\n",
              "      <td>20.376535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-01 04:00:00</th>\n",
              "      <td>LOC_001</td>\n",
              "      <td>89</td>\n",
              "      <td>0.936667</td>\n",
              "      <td>15.922471</td>\n",
              "      <td>145</td>\n",
              "      <td>52.258779</td>\n",
              "      <td>summer</td>\n",
              "      <td>1</td>\n",
              "      <td>1.094965</td>\n",
              "      <td>1</td>\n",
              "      <td>0.512834</td>\n",
              "      <td>medium</td>\n",
              "      <td>-6.068825</td>\n",
              "      <td>-4.793058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-01 05:00:00</th>\n",
              "      <td>LOC_001</td>\n",
              "      <td>278</td>\n",
              "      <td>0.900152</td>\n",
              "      <td>26.343416</td>\n",
              "      <td>141</td>\n",
              "      <td>70.581182</td>\n",
              "      <td>spring</td>\n",
              "      <td>1</td>\n",
              "      <td>1.822836</td>\n",
              "      <td>0</td>\n",
              "      <td>0.589076</td>\n",
              "      <td>medium</td>\n",
              "      <td>-30.603321</td>\n",
              "      <td>2.003588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-01 06:00:00</th>\n",
              "      <td>LOC_003</td>\n",
              "      <td>597</td>\n",
              "      <td>0.975164</td>\n",
              "      <td>20.676569</td>\n",
              "      <td>134</td>\n",
              "      <td>54.193750</td>\n",
              "      <td>summer</td>\n",
              "      <td>1</td>\n",
              "      <td>6.011548</td>\n",
              "      <td>0</td>\n",
              "      <td>0.786082</td>\n",
              "      <td>medium</td>\n",
              "      <td>-1.928188</td>\n",
              "      <td>-13.306153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-01 07:00:00</th>\n",
              "      <td>LOC_002</td>\n",
              "      <td>969</td>\n",
              "      <td>0.832066</td>\n",
              "      <td>31.490696</td>\n",
              "      <td>47</td>\n",
              "      <td>87.103858</td>\n",
              "      <td>spring</td>\n",
              "      <td>0</td>\n",
              "      <td>9.026858</td>\n",
              "      <td>0</td>\n",
              "      <td>0.900533</td>\n",
              "      <td>high</td>\n",
              "      <td>-22.911472</td>\n",
              "      <td>6.416325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-01 08:00:00</th>\n",
              "      <td>LOC_003</td>\n",
              "      <td>272</td>\n",
              "      <td>0.609609</td>\n",
              "      <td>16.484817</td>\n",
              "      <td>30</td>\n",
              "      <td>62.670967</td>\n",
              "      <td>spring</td>\n",
              "      <td>0</td>\n",
              "      <td>3.584483</td>\n",
              "      <td>0</td>\n",
              "      <td>0.440805</td>\n",
              "      <td>low</td>\n",
              "      <td>15.556006</td>\n",
              "      <td>3.516501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-01 09:00:00</th>\n",
              "      <td>LOC_003</td>\n",
              "      <td>55</td>\n",
              "      <td>0.518366</td>\n",
              "      <td>19.527030</td>\n",
              "      <td>66</td>\n",
              "      <td>35.370598</td>\n",
              "      <td>autumn</td>\n",
              "      <td>0</td>\n",
              "      <td>3.949725</td>\n",
              "      <td>1</td>\n",
              "      <td>0.286683</td>\n",
              "      <td>low</td>\n",
              "      <td>-4.017957</td>\n",
              "      <td>-26.208872</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23046d6a-d1d5-47dd-a321-08cc72889c4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23046d6a-d1d5-47dd-a321-08cc72889c4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23046d6a-d1d5-47dd-a321-08cc72889c4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-882d5522-74a5-4e17-9b21-7c8a8c182343\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-882d5522-74a5-4e17-9b21-7c8a8c182343')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-882d5522-74a5-4e17-9b21-7c8a8c182343 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"2024-12-22 17:00:00\",\n          \"2024-12-31 17:00:00\",\n          \"2024-12-31 20:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"LOC_003\",\n          \"LOC_001\",\n          \"LOC_002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"visitor_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 281,\n        \"min\": 50,\n        \"max\": 999,\n        \"num_unique_values\": 605,\n        \"samples\": [\n          359,\n          727,\n          866\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resource_usage_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19918270058496096,\n        \"min\": 0.3001318796896073,\n        \"max\": 0.9979547099571632,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          0.4238210016006981,\n          0.42143605198617,\n          0.4247767268332491\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.758527362493416,\n        \"min\": 15.008855628744158,\n        \"max\": 34.99427608311828,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          19.09962419053633,\n          32.009432295216754,\n          16.037905990368216\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"air_quality_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37,\n        \"min\": 20,\n        \"max\": 149,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          98,\n          73,\n          67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noise_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.91609819200633,\n        \"min\": 30.01305697194642,\n        \"max\": 99.82626918208724,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          92.05517686493316,\n          55.05728361729352,\n          39.6857740621733\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"autumn\",\n          \"spring\",\n          \"summer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"peak_hour_flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"visitor_satisfaction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.5542907651556304,\n        \"min\": 1.014410687941259,\n        \"max\": 9.9977640708614,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          5.896269687651181,\n          5.578227466564384\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sensor_noise_flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resource_prediction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17456047598052193,\n        \"min\": 0.1843013987520383,\n        \"max\": 0.976714556986186,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          0.553410500800349,\n          0.643718025993085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resource_allocation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"high\",\n          \"low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t_sne_dim1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.179541830454724,\n        \"min\": -34.30869,\n        \"max\": 36.515007,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          9.565732,\n          22.80191\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t_sne_dim2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.797633471480655,\n        \"min\": -38.91482,\n        \"max\": 33.65287,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          -14.902231,\n          1.6327542\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Viewing the data\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3RpjmUS21M"
      },
      "source": [
        "**Constructing the text data**\n",
        "\n",
        "It's useful to use both `Title` and `Description`. To help downstream models understand which content is title and which content is description, we will add a prefix explaining which section is title and which is description. So each row should look like\n",
        "\n",
        "```\n",
        "Title\n",
        "{Title}\n",
        "Description\n",
        "{Description}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRjed6aXUo6j"
      },
      "source": [
        "### STEP 2: Vector Store Setup\n",
        "\n",
        "Let's try to get a few of the basic questions answered about vector stores before we start using it.\n",
        "\n",
        "### What is a vector store?\n",
        "A vector store is a specialized database that stores data in the form of numerical vectors, allowing efficient searching and retrieval based on similarity rather than exact matches.\n",
        "\n",
        "### Why do we need a vector store?\n",
        "Traditional databases rely on exact keyword matches, which can miss relevant information. A vector store helps find similar content by understanding relationships and meaning in data.\n",
        "\n",
        "### How does a vector store work?\n",
        "It converts text, images, or other data into numerical vectors using ML\n",
        " models, then stores these vectors and retrieves similar ones using techniques like cosine similarity.\n",
        "\n",
        "### How does a vector store improve search results?\n",
        "It enables searches based on meaning rather than just keywords, providing more relevant results even if the exact terms don't match.\n",
        "\n",
        "### What are some popular vector store tools?\n",
        "- FAISS (Facebook AI Similarity Search)\n",
        "- Pinecone\n",
        "- Weaviate\n",
        "- Chroma\n",
        "\n",
        "### What is an embedding, and how does it relate to a vector store?\n",
        "An embedding is a numerical representation of data (e.g., text, image) that captures its meaning. These embeddings are stored in a vector store for efficient retrieval.\n",
        "\n",
        "\n",
        "Our next step is\n",
        "-  to convert the `product_description` to chunks\n",
        "-  convert each chunk to embedding\n",
        "-  store it in vector store for searching\n",
        "\n",
        "As discussed earlier we shall use `LangChain` to perform these steps.\n",
        "\n",
        "LangChain is a framework that helps developers build applications powered by large language models (LLMs) like GPT by providing tools for various tasks to be carried out like retrieving relevant information from databases, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hwFdqweOT2xI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "dbc92032-ba7f-4bfd-d458-c40d715405a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Importing RecursiveCharacterTextSplitter from LangChain for chunking large text into smaller, manageable pieces.\n",
        "# This helps in optimizing text for processing and retrieval.\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Importing OpenAIEmbeddings from LangChain to generate numerical vector representations (embeddings) of text.\n",
        "# These embeddings capture the semantic meaning of the text for efficient similarity searches.\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Importing FAISS (Facebook AI Similarity Search) from LangChain's community package.\n",
        "# FAISS is used for storing and retrieving embeddings efficiently by finding similar vectors.\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Importing the OpenAI library to interact with OpenAI's API services.\n",
        "from openai import OpenAI\n",
        "\n",
        "import os  # Importing the os module to interact with environment variables\n",
        "import getpass  # Importing getpass to securely input sensitive information\n",
        "\n",
        "# Prompting the user to securely enter their OpenAI API key without displaying it on the screen\n",
        "OPENAI_API_KEY = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "# Setting the OpenAI API key as an environment variable.\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2X3hxmTTUsr1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ee69d435-9b6a-436d-d8cc-695acf38ee0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Location LOC_003 had 808 visitors. Resource usage rate: 0.9076380257726048%. Temperature: 19.368863657666143°C, AQI: 127, Noise level: 51.50672732934044 dB. Season: summer, Peak hour: 0. Visitor satisfaction: 5.502614668103616, Resource prediction:'\n"
          ]
        }
      ],
      "source": [
        "# Setting the OpenAI API key as an environment variable.\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "# Convert each row into a readable string for embeddings\n",
        "texts = df.apply(lambda row: (\n",
        "    f\"Location {row['location_id']} had {row['visitor_count']} visitors. \"\n",
        "    f\"Resource usage rate: {row['resource_usage_rate']}%. \"\n",
        "    f\"Temperature: {row['temperature']}°C, AQI: {row['air_quality_index']}, Noise level: {row['noise_level']} dB. \"\n",
        "    f\"Season: {row['season']}, Peak hour: {row['peak_hour_flag']}. \"\n",
        "    f\"Visitor satisfaction: {row['visitor_satisfaction']}, Resource prediction: {row['resource_prediction']} units.\"\n",
        "), axis=1).tolist()\n",
        "\n",
        "# Split text into documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=250,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "documents = text_splitter.create_documents(texts)\n",
        "\n",
        "# Show a sample document\n",
        "print(documents[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation:\n",
        "The above code initializes a `RecursiveCharacterTextSplitter` to break down product_description into smaller text chunks of 250 characters each, with a 20-character overlap to preserve context between chunks. The `create_documents` function processes the text list and generates structured document chunks for efficient retrieval and analysis.\n",
        "\n",
        "### Why do we need overlap?\n",
        "Overlap is needed to ensure continuity and preserve context between chunks, preventing important information from being cut off at chunk boundaries. This helps LLMs better understand the text when processing each chunk independently, improving retrieval accuracy and response quality."
      ],
      "metadata": {
        "id": "MqtfA0tXh7CL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ptE8XpNLWD--"
      },
      "outputs": [],
      "source": [
        "# Create an embedding model using LangChain.\n",
        "# One option is using https://python.langchain.com/docs/integrations/text_embedding/openai/\n",
        "# See https://python.langchain.com/docs/integrations/text_embedding/ for a list of available embedding models on LangChain\n",
        "embeddings = OpenAIEmbeddings()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sSlO9vblWGDt"
      },
      "outputs": [],
      "source": [
        "# Create a vector store using the created chunks and the embeddings model\n",
        "vector = FAISS.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What have we done so far?\n",
        "1. Data Preparation: Extracted the product description data\n",
        "2. Data Chunking: Converted the entire data into multiple manageable chunks\n",
        "3. Chunks to Embeddings: Converted the broken down chunks into embeddings\n",
        "4. Storage in a Vector DB: Stored the resulting embeddings of chunks in a vector store for effective retrieval.\n",
        "\n",
        "\n",
        "### What is remaining?\n",
        "- Building the chatbot\n",
        "- Building the Gradio UI"
      ],
      "metadata": {
        "id": "nNhCKF9Nig_n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c24S9JsfWSa7"
      },
      "source": [
        "### STEP 3: Building the chatbot\n",
        "\n",
        "Now that we have converted the documents to embeddings, our next step is to\n",
        "- build a retriever that uses the vector store to retrieve the documents\n",
        "- create a prompt template that contains the augmented context using the retrieved documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nElsMdbeW4l1"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableMap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code Explanation:\n",
        "- `ChatOpenAI` – Used to access OpenAI models for chatbot functionality.\n",
        "- `ChatPromptTemplate` – Helps structure queries to ensure better responses.\n",
        "- `OpenAIEmbeddings` – Converts text into vector form for similarity-based retrieval.\n",
        "- `create_stuff_documents_chain` – Combines retrieved documents meaningfully before passing to the LLM.\n",
        "- `create_retrieval_chain` – Automates the process of retrieving and utilizing relevant content for AI responses.\n",
        "- `StrOutputParser` - For processing the output of language models, ensuring that the output is returned as a plain string"
      ],
      "metadata": {
        "id": "xVChvJAijx-1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6dJXzILCXStu"
      },
      "outputs": [],
      "source": [
        "# Initializing the ChatOpenAI model to interact with OpenAI's GPT model.\n",
        "llm = ChatOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], model = 'gpt-4o-mini')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the output parser to process and format the model's response into a readable string format.\n",
        "output_parser = StrOutputParser()\n",
        "chat_history = []\n",
        "# Creating a prompt template that instructs the LLM to act as a customer service agent.\n",
        "# The prompt takes two parameters:\n",
        "#   1. {context} - Relevant information retrieved from the document store.\n",
        "#   2. {input} - The user's question.\n",
        "# The model is instructed to base its answer solely on the provided context.\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"You are a helpful assistant. Use the following context and chat history to answer the question.\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "<chat_history>\n",
        "{chat_history}\n",
        "</chat_history>\n",
        "\n",
        "Question: {input}\"\"\"\n",
        ")\n",
        "\n",
        "# Create a retriever from the vector store for fetching relevant documents\n",
        "# See https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/vectorstore/\n",
        "retriever = vector.as_retriever()\n",
        "\n",
        "# Creating a document processing chain using the LLM and the defined prompt\n",
        "# template.\n",
        "# This chain takes a list of retrieved documents and passes them as context to\n",
        "# the model for generating responses.\n",
        "\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "rag_chain = (\n",
        "    RunnableMap({\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "        \"context\": lambda x: \"\\n\".join([doc.page_content for doc in retriever.invoke(x[\"input\"])])\n",
        "    })\n",
        "    | prompt\n",
        "    | llm\n",
        "    | output_parser\n",
        ")\n",
        "\n",
        "def format_chat_history(history):\n",
        "    return \"\\n\".join([f\"User: {q}\\nBot: {a}\" for q, a in history])\n"
      ],
      "metadata": {
        "id": "dPJ3yFeEk9EN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wUqxhEW3XcJX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "648b33db-b4a6-41da-9326-a039284ac0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location LOC_001 has the top number of visitors, with 970 visitors.\n"
          ]
        }
      ],
      "source": [
        "# Invoking the retrieval chain to process the user's query.\n",
        "# The query \"what are some of the best shoes available?\" is passed as input.\n",
        "# The retrieval chain first fetches relevant product descriptions from the vector store,\n",
        "# then processes them using the document chain to generate a meaningful LLM response.\n",
        "user_query = \"what location has the top visitors?\"\n",
        "formatted_history = format_chat_history(chat_history)\n",
        "\n",
        "response = rag_chain.invoke({\n",
        "    \"input\": user_query,\n",
        "    \"chat_history\": formatted_history\n",
        "})\n",
        "\n",
        "chat_history.append((user_query, response))\n",
        "print(response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QqNvod6GXfjx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c1f5ffe3-2012-4930-dea6-e2759ecfd9b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The season with the top visitors is summer, as it had 970 visitors at Location LOC_001.\n"
          ]
        }
      ],
      "source": [
        "# Fetching the final answer from the retrieval chain by invoking it with a user query.\n",
        "# The ['answer'] key extracts the final LLM-generated answer from the response dictionary.\n",
        "user_query = \"what season has the top visitors?\"\n",
        "formatted_history = format_chat_history(chat_history)\n",
        "\n",
        "response = rag_chain.invoke({\n",
        "    \"input\": user_query,\n",
        "    \"chat_history\": formatted_history\n",
        "})\n",
        "\n",
        "chat_history.append((user_query, response))\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we got the answer! But, the formatting is not very good, right? Lets create a simple UI for our bot."
      ],
      "metadata": {
        "id": "2tMQ3SGUnoad"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvDsSk-bYSwS"
      },
      "source": [
        "### STEP 4: Building a simple Gradio UI\n",
        "\n",
        "Gradio is an open-source Python library that makes it easy to build interactive user interfaces for machine learning models, APIs, and data science workflows. It allows developers to create shareable web-based UIs with just a few lines of code.\n",
        "\n",
        "To build the gradio app we'll utilize the following steps:\n",
        "\n",
        "- Modularize the entire RAG pipeline using a single function\n",
        "- Create the building blocks for the UI.\n",
        "- Connect the UI with the function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define a function to run the full RAG process\n",
        "def final_response(user_query):\n",
        "    formatted_history = format_chat_history(chat_history)\n",
        "\n",
        "    # Step 1: Retrieve context\n",
        "    context_docs = retriever.invoke(user_query)\n",
        "    context_text = \"\\n\".join([doc.page_content for doc in context_docs])\n",
        "\n",
        "    # Step 2: Format the prompt with all variables\n",
        "    prompt_input = {\n",
        "        \"input\": user_query,\n",
        "        \"context\": context_text,\n",
        "        \"chat_history\": formatted_history\n",
        "    }\n",
        "    formatted_prompt = prompt.invoke(prompt_input)\n",
        "\n",
        "    # Step 3: Run LLM on formatted prompt\n",
        "    response = llm.invoke(formatted_prompt)\n",
        "    parsed_response = output_parser.invoke(response)\n",
        "\n",
        "    # Step 4: Save to history\n",
        "    chat_history.append((user_query, parsed_response))\n",
        "\n",
        "    return parsed_response\n",
        "\n",
        "def chatbot_fn(message, history):\n",
        "    # Format history for prompt\n",
        "    formatted_history = format_chat_history(chat_history)\n",
        "\n",
        "    # Run RAG pipeline\n",
        "    response = rag_chain.invoke({\n",
        "        \"input\": message,\n",
        "        \"chat_history\": formatted_history\n",
        "    })\n",
        "\n",
        "    # Save to history\n",
        "    chat_history.append((message, response))\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "PcAbbKmKoHZO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "chatbot_ui = gr.ChatInterface(\n",
        "    fn=chatbot_fn,\n",
        "    title=\"Echo Tourism RAG Bot\",\n",
        "    description=\"Ask me anything about eco-tourism and sustainability!\",\n",
        "    theme=\"soft\",\n",
        ")\n",
        "\n",
        "chatbot_ui.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "WQDHJzbJ_i3v",
        "outputId": "90c77026-a5a3-4ec3-9a2a-172951dfae36"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6b4a6f94603c892130.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b4a6f94603c892130.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YqDgfrpU_fnv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next Steps for Experimentation\n",
        "\n",
        "In the above demonstration, we have created a very basic GUI-based RAG app. Before our next class, you are recommende to experiment the following\n",
        "\n",
        "- Try asking 10-15 questions and check the accuracy of the response.\n",
        "- What would be a strategy that you might follow to evaluate the app's overall responses?\n",
        "- Ask a few out-of-the-box questions (like \"What is the weather today in Seattle?\")\n",
        "- Try asking the same question multiple times with a different wording\n",
        "- In the same chat history, ask questions which are related to the response that was just provided.\n",
        "- Use a different dataset (perhaps in a different format like pdf) and see how the architecture might change.\n",
        "\n",
        "<hr> <hr>"
      ],
      "metadata": {
        "id": "5BG7LdhktfTq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}